{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP1Y3D5T2RK7Id4pf9OOMWG"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"BH4FAtXP2zdG"},"outputs":[],"source":["!wget https://github.com/korakot/kora/releases/download/v0.10/py310.sh\n","!bash ./py310.sh -b -f -p /usr/local\n","!python -m ipykernel install --name \"py310\" --user"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","import sys\n","print('version',sys.version)"],"metadata":{"id":"DrBmqroX20nc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install networkx[default]\n","!pip install torch\n","!pip install lxml\n","!pip install numpy"],"metadata":{"id":"1c7B6-dM274E"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import json\n","import numpy as np\n","import networkx as nx\n","import copy\n","import matplotlib.pyplot as plt\n","from xml.dom.minidom import parse, Document\n","import os\n","from matplotlib.pyplot import MultipleLocator\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","\n","def get_text(node):\n","    rc = []\n","    for node in node.childNodes:\n","        if node.nodeType == node.TEXT_NODE:\n","            rc.append(node.data)\n","    return \"\".join(rc).strip()\n","\n","\n","def bpmn_to_graph(root_dom: Document, prefix: str = \"bpmn\"):\n","    task_nodes = root_dom.getElementsByTagName(f\"{prefix}task\")\n","    seq_flows = root_dom.getElementsByTagName(f\"{prefix}sequenceFlow\")\n","    par_gateways = root_dom.getElementsByTagName(f\"{prefix}parallelGateway\")\n","    exc_gateways = root_dom.getElementsByTagName(f\"{prefix}exclusiveGateway\")\n","\n","    all_tasks = task_nodes\n","    name_nodes_set = {}\n","    sorted_task_nodes = []\n","    sorted_name = []\n","\n","    for i in range(len(all_tasks)):\n","      task_name = all_tasks[i].getAttribute(\"name\")\n","      name_nodes_set[task_name] = all_tasks[i]\n","\n","    for j in range(len(all_tasks)):\n","      name = all_tasks[j].getAttribute(\"name\")\n","      sorted_name.append(name)\n","    sorted_name = sorted(sorted_name, key=str.lower) #返回字母顺序排列的列表\n","\n","    for k in range(len(all_tasks)):\n","      name_key = sorted_name[k]\n","      nodes_value = name_nodes_set.get(name_key)\n","      sorted_task_nodes.append(nodes_value)\n","\n","    node_list =  sorted_task_nodes + par_gateways + exc_gateways\n","\n","\n","    seq_flow_ids = []\n","    par_gateway_ids = []\n","    exc_gateway_ids = []\n","\n","    G = nx.DiGraph()\n","    for node in node_list + seq_flows:\n","        node_type = node.tagName\n","        node_id = node.getAttribute(\"id\")\n","        node_name = node.getAttribute(\"name\")\n","\n","        if node_type == f\"{prefix}sequenceFlow\":\n","            seq_flow_ids.append(node_id)\n","        elif node_type == f\"{prefix}parallelGateway\":\n","            par_gateway_ids.append(node_id)\n","        elif node_type == f\"{prefix}exclusiveGateway\":\n","            exc_gateway_ids.append(node_id)\n","\n","        G.add_node(node_id, type=node_type, name=node_name)\n","\n","    for node in node_list:\n","        node_id = node.getAttribute(\"id\")\n","\n","        # for child in node.childNodes:\n","        #     if child.nodeType == child.TEXT_NODE:\n","        #         continue\n","        #     assert child.tagName in [f\"{prefix}incoming\", f\"{prefix}outgoing\", \"extensionElements\"]\n","        #     child_id = get_text(child)\n","        #     if child.tagName == f\"{prefix}incoming\":\n","        #         G.add_edge(child_id, node_id)\n","        #     elif child.tagName == f\"{prefix}outgoing\":\n","        #         G.add_edge(node_id, child_id)\n","        for child in node.childNodes:\n","            if child.nodeType == child.TEXT_NODE:\n","                continue\n","            if child.tagName not in [f\"{prefix}incoming\", f\"{prefix}outgoing\",\n","                \"extensionElements\", f\"{prefix}dataOutputAssociation\",\n","                f\"{prefix}standardLoopCharacteristics\", f\"{prefix}multiInstanceLoopCharacteristics\",\n","                 f\"{prefix}property\", f\"{prefix}dataInputAssociation\"]:\n","                # 在这里进行相应的操作或输出错误信息\n","                print(\"Invalid tag name:\", child.tagName)\n","            child_id = get_text(child)\n","            if child.tagName == f\"{prefix}incoming\":\n","                G.add_edge(child_id, node_id)\n","            elif child.tagName == f\"{prefix}outgoing\":\n","                G.add_edge(node_id, child_id)\n","\n","\n","    for node_id in seq_flow_ids + exc_gateway_ids:\n","        for predecessor in G.predecessors(node_id):\n","            for successor in G.successors(node_id):\n","                G.add_edge(predecessor, successor)\n","\n","        G.remove_node(node_id)\n","\n","    for node_id in par_gateway_ids:\n","        for predecessor in G.predecessors(node_id):\n","            for successor in G.successors(node_id):\n","                G.add_edge(predecessor, successor, is_par=True)\n","\n","        G.remove_node(node_id)\n","\n","    H = copy.deepcopy(G)\n","\n","    while not nx.is_directed_acyclic_graph(G):\n","        cycle = nx.find_cycle(G, orientation=\"original\")\n","        G.remove_edge(*cycle[-1][:2])\n","\n","    for (u, v), lca in nx.all_pairs_lowest_common_ancestor(G):\n","        if u == lca or v == lca:\n","            continue\n","\n","        ok_u = False\n","        for path in nx.all_simple_paths(G, lca, u):\n","            if len(path) > 0:\n","                attrs = G.get_edge_data(path[0], path[1])\n","                if \"is_par\" in attrs and attrs[\"is_par\"]:\n","                    ok_u = True\n","\n","        ok_v = False\n","        for path in nx.all_simple_paths(G, lca, v):\n","            if len(path) > 0:\n","                attrs = G.get_edge_data(path[0], path[1])\n","                if \"is_par\" in attrs and attrs[\"is_par\"]:\n","                    ok_v = True\n","\n","        if ok_u and ok_v:\n","            H.add_edge(u, v)\n","            H.add_edge(v, u)\n","\n","    return H\n","\n","\n","\n","def read_json_file(filepath):\n","    with open(filepath, 'r', encoding='utf-8') as file:\n","        return json.load(file)\n","\n","\n","def json_to_graph(json_data):\n","    task_id = []\n","    seq_flow_id = []\n","    par_gateway_id = []\n","    exc_gateway_id = []\n","    task_name = []\n","    name_id_set = {}\n","    sorted_name = []\n","\n","    gateways_list = json_data['gateways']\n","    for gateway in gateways_list:\n","        gateway_id = gateway['id']\n","        gateway_type = gateway['type']\n","        if gateway_type == 'XOR':\n","            exc_gateway_id.append(gateway_id)\n","        elif gateway_type == 'AND':\n","            par_gateway_id.append(gateway_id)\n","\n","    flows_list = json_data['flows']\n","\n","    task_list = json_data['tasks']\n","    for task in task_list:\n","        id = task['id']\n","        name = task['label']\n","        if name != 'ENTRY' and name != 'EXIT':\n","          name_id_set[name] = id\n","          task_name.append(name)\n","    sorted_name = sorted(task_name, key = str.lower)\n","\n","    for i in range(len(sorted_name)):\n","      name_key = sorted_name[i]\n","      id_value = name_id_set.get(name_key)\n","      task_id.append(id_value)\n","\n","    G = nx.DiGraph()\n","    #task的id先存放起来，已知的还有flow列表，其中包含targ和src，网关也只有id，\n","    #思路：现将task_id添加到graph中，之后遍历边\n","\n","    for node_id in task_id+par_gateway_id+exc_gateway_id:\n","        G.add_node(node_id)\n","\n","    for seq in flows_list:\n","        src_id = seq[\"src\"]\n","        tgt_id = seq[\"tgt\"]\n","        G.add_edge(src_id, tgt_id)\n","\n","    for node_id in exc_gateway_id:\n","        for predecessor in G.predecessors(node_id):\n","          for successor in G.successors(node_id):\n","              G.add_edge(predecessor, successor)\n","\n","        G.remove_node(node_id)\n","\n","    for node_id in par_gateway_id:\n","        for predecessor in G.predecessors(node_id):\n","          for successor in G.successors(node_id):\n","              G.add_edge(predecessor, successor, is_par=true)\n","\n","        G.remove_node(node_id)\n","\n","\n","    H = copy.deepcopy(G)\n","\n","    while not nx.is_directed_acyclic_graph(G):\n","        cycle = nx.find_cycle(G, orientation=\"original\")\n","        G.remove_edge(*cycle[-1][:2])\n","\n","    #通过寻找u，v的最早祖先lca，通过判断lca是否为平行网关，来实现u，v两边的平行\n","    for (u, v), lca in nx.all_pairs_lowest_common_ancestor(G):\n","        if u == lca or v == lca:\n","            continue\n","\n","        ok_u = False\n","        for path in nx.all_simple_paths(G, lca, u):\n","            if len(path) > 0:\n","                attrs = G.get_edge_data(path[0], path[1])\n","                if \"is_par\" in attrs and attrs[\"is_par\"]:\n","                    ok_u = True\n","\n","        ok_v = False\n","        for path in nx.all_simple_paths(G, lca, v):\n","            if len(path) > 0:\n","                attrs = G.get_edge_data(path[0], path[1])\n","                if \"is_par\" in attrs and attrs[\"is_par\"]:\n","                    ok_v = True\n","\n","        if ok_u and ok_v:\n","            H.add_edge(u, v)\n","            H.add_edge(v, u)\n","\n","    for node in task_list:\n","        node_name = node['label']\n","        if(node_name=='ENTRY' or node_name == 'EXIT'):\n","          node_id = node['id']\n","          H.remove_node(node_id)\n","\n","    return H\n","\n","\n","def jsonNameList(json_data):\n","    task_name = []\n","    task_list = json_data['tasks']\n","    for node in task_list:\n","      node_name = node['label']\n","      if(node_name == 'ENTRY' or node_name=='EXIT'):\n","        continue\n","      if node_name in task_name:\n","        continue\n","      task_name.append(node_name)\n","\n","    task_name = sorted(task_name, key = str.lower)\n","    return task_name\n","\n","\n","\n","\n","def sortedNameList(root_dom: Document):\n","    #传递一个bpmn文件返回他对应的排序好的结点列表\n","    task = root_dom.getElementsByTagName(\"task\") #注意进行前缀的替换\n","    #other_tasks = [node for node in root_dom.getElementsByTagName(\"*\") if node.nodeName.endswith(\"Task\")]\n","    task_nodes = task\n","    sorted_name_list = []\n","    for element in task_nodes:\n","        name = element.getAttribute('name')\n","        sorted_name_list.append(name)\n","    sorted_name = sorted(sorted_name_list, key= str.lower)\n","    return sorted_name #返回每个root_dom中task列表\n","\n","def twoGraphList(graph1_list,graph2_list):\n","    finalList = graph1_list+graph2_list\n","    finalList = list(set(finalList)) #调用内置set函数实现对列表重复元素的删除\n","    finalList = sorted(finalList, key= str.lower)\n","    return finalList #返回两个图排序好的name列表\n","\n","\n","def getEmbedding(graph_list, finalList):\n","    '''\n","      对传递进来的图的task进行one-hot编码\n","    '''\n","    graphFeature = []\n","    for i in range(len(finalList)):\n","      nodeFeature = [0]*(len(finalList))\n","      graphFeature.append(nodeFeature)\n","    for name in graph_list:\n","      if name in finalList:\n","        index = finalList.index(name)\n","        graphFeature[index][index] = 1\n","    graphTensor = torch.tensor(graphFeature)\n","    return graphTensor\n","\n","\n","def normalized_adj_matrix(graph1_name_list, final_list, graph1_adj_list):\n","    list_index = []\n","    for name in graph1_name_list:\n","      if name in final_list:\n","        index = final_list.index(name)\n","        list_index.append(index)\n","    list_index.sort()\n","\n","    graph1_normalized_list=[]\n","    for i in range(len(final_list)):\n","      nodeFeature = [0]*(len(final_list))\n","      graph1_normalized_list.append(nodeFeature)\n","    for i in range(len(graph1_name_list)):\n","      x = list_index[i]\n","      for j in range(len(graph1_name_list)):\n","        y = list_index[j]\n","        if(graph1_adj_list[i][j]==1):\n","          graph1_normalized_list[x][y] = 1\n","    tensor = torch.Tensor(graph1_normalized_list)\n","    return tensor\n","\n","def getCost(name1, name2, adj_matrix1, adj_matrix2):\n","      # 将两个列表转换为集合\n","      set1 = set(name1)\n","      set2 = set(name2)\n","\n","      # 找到两个集合中的不同元素\n","      difference = list(set1.symmetric_difference(set2))\n","      cost = 10*(len(difference))\n","\n","      for i in range(len(adj_matrix1)):\n","        for j in range(len(adj_matrix1)):\n","          if adj_matrix1[i][j] != adj_matrix2[i][j]:\n","            cost += 1\n","\n","      return cost\n","\n","def normalize(A): #加上自连接  A = A+I\n","    A = torch.eye(A.shape[0]) + A  #返回一个n*n的张量，对角线位置全1，其它位置全0\n","    d = A.sum(1)  # 所有节点的度，求数组每一行的和\n","    D = torch.diag(torch.pow(d, -0.5))\n","    return torch.matmul(torch.matmul(D, A), D)  #D^(-1/2)*A*D^(-1/2)\n","\n","def expendDimension(X):\n","    tensor = torch.zeros(50,50)\n","    zero_list = tensor.numpy().tolist()\n","    X_list = X.numpy().tolist()\n","    index = len(X_list[0])\n","    for i in range(index):\n","      for j in range(index):\n","        zero_list[i][j]+= X_list[i][j]\n","    return torch.tensor(zero_list)\n","\n","class GCN(nn.Module):  #来增强特征；引入虚拟节点，通过不断循环，获得该图中各个节点的特征。最后将两个图的虚拟节点拿来做对比\n","    def __init__(self, dim_in, dim_out):\n","        super(GCN, self).__init__()\n","        self.fc1 = nn.Linear(dim_in, dim_in, bias=False)  #全连接层 首先初始化一个全连接神经网络\n","        self.fc2 = nn.Linear(dim_in, dim_in, bias=False)\n","    def forward(self, X, A):  #X是特征矩阵 A是邻接矩阵 矩阵相乘 X和A相乘(新方法)  A和X相乘(旧方法)\n","        X_copy = X.clone()  # 复制一份输入Tensor\n","        X = self.fc1(X.mm(A))\n","        X = X_copy + X  # 加入残差连接\n","        X = F.relu(X)\n","        X_copy = X.clone()  # 复制一份输出Tensor\n","        X = self.fc2(X.mm(A))\n","        X = X_copy + X  # 加入残差连接\n","        X = F.relu(X)\n","        return X\n","\n","\n","def euclidean_distance(x, y):\n","    \"\"\"This is the squared Euclidean distance.\"\"\"\n","    return torch.sqrt( torch.sum(torch.pow(x-y, 2) ) )\n","\n","\n","\n","\n","def main():\n","    json_file = '/content/input.struct.json'\n","    json_data = read_json_file(json_file)\n","    G_json = json_to_graph(json_data)\n","    json_adj = np.asarray(nx.adjacency_matrix(G_json).todense())\n","    json_name = jsonNameList(json_data)\n","\n","\n","    dom = '/content/struct_model.bpmn'\n","    root = parse(dom)\n","    G = bpmn_to_graph(root, prefix = '')\n","    G_adj = np.asarray(nx.adjacency_matrix(G).todense())\n","    name = sortedNameList(root)\n","\n","    nameList = twoGraphList(name, json_name)\n","\n","    json_embedding = getEmbedding(json_name, nameList)\n","    bpmn_embedding = getEmbedding(name, nameList)\n","    json_embedding_amend = expendDimension(json_embedding)\n","    bpmn_embedding_amend = expendDimension(bpmn_embedding)\n","\n","    json_normalize = normalized_adj_matrix(json_name, nameList, json_adj)\n","    json_Laplace = normalize(json_normalize)\n","    json_Laplace_amend = expendDimension(json_Laplace)\n","\n","    bpmn_normalize = normalized_adj_matrix(name, nameList, G_adj)\n","    bpmn_Laplace = normalize(bpmn_normalize)\n","    bpmn_Laplace_amend = expendDimension(bpmn_Laplace)\n","\n","    gcn = GCN(50,50)\n","    f1 = gcn(json_embedding_amend, json_Laplace_amend)\n","    f2 = gcn(bpmn_embedding_amend, bpmn_Laplace_amend)\n","\n","    distance = euclidean_distance(f1, f2)\n","    print(distance)\n","\n","\n","\n","\n","\n","if __name__ == '__main__':\n","    main()"],"metadata":{"id":"5gcgAU453CaR"},"execution_count":null,"outputs":[]}]}